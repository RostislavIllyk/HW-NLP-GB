{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60119c00",
   "metadata": {},
   "source": [
    "# HW 9 TWO HEADS VAR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d64d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6edcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'evgenyi_onegin.txt'\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "text = text.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c215589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                        \"Мой дядя самых честных правил,\\n                        Когда не в шутку занемог,\\n                        Он уважать себя заставил\\n                        И лучше выдумать не мог.\\n                        Его пример другим наука;\\n                        Но, боже мой, какая скука\\n                        С больным сидеть и день и ночь,\\n                        Не отходя ни шагу прочь!\\n                        Какое низкое коварство\\n                        Полуживого забавлять,\\n                        Ему подушки поправлять,\\n                        Печально подносить лекарство,\\n                        Вздыхать и думать про себя:\\n                        Когда же черт возьмет тебя!\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a510643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61a67cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only = []\n",
    "for strofa in text:\n",
    "    if len(strofa) < 350:\n",
    "        continue\n",
    "    else:\n",
    "        text_only.append(strofa)\n",
    "len(text_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe08a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                        Кого ж любить? Кому же верить?\\n                        Кто не изменит нам один?\\n                        Кто все дела, все речи мерит\\n                        Услужливо на наш аршин?\\n                        Кто клеветы про нас не сеет?\\n                        Кто нас заботливо лелеет?\\n                        Кому порок наш не беда?\\n                        Кто не наскучит никогда?\\n                        Призрака суетный искатель,\\n                        Трудов напрасно не губя,\\n                        Любите самого себя,\\n                        Достопочтенный мой читатель!\\n                        Предмет достойный: ничего\\n                        Любезней, верно, нет его.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only[155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3482a215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не мысля гордый свет з...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Мой дядя самых честны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Так думал молодой пове...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Служив отлично благоро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Когда же юности мятежн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>А счастье было так воз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Она ушла. Стоит Евгени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Кто б ни был ты, о мой...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Прости ж и ты, мой спу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Но те, которым в дружн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content\n",
       "0                            Не мысля гордый свет з...\n",
       "1                            \"Мой дядя самых честны...\n",
       "2                            Так думал молодой пове...\n",
       "3                            Служив отлично благоро...\n",
       "4                            Когда же юности мятежн...\n",
       "..                                                 ...\n",
       "371                          А счастье было так воз...\n",
       "372                          Она ушла. Стоит Евгени...\n",
       "373                          Кто б ни был ты, о мой...\n",
       "374                          Прости ж и ты, мой спу...\n",
       "375                          Но те, которым в дружн...\n",
       "\n",
       "[376 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(text_only)\n",
    "data = data.rename(columns={0: \"Content\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779d81bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_splited</th>\n",
       "      <th>Content_splited_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не мысля гордый свет з...</td>\n",
       "      <td>[не, мысля, гордый, свет, забавить,  \\n, внима...</td>\n",
       "      <td>[не, мыслить, гордый, свет, забавить,  \\n, вни...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Мой дядя самых честны...</td>\n",
       "      <td>[мой, дядя, самых, честных, правил,  \\n, когда...</td>\n",
       "      <td>[мой, дядя, самый, честной, правило,  \\n, когд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Так думал молодой пове...</td>\n",
       "      <td>[так, думал, молодой, повеса,  \\n, летя, в, пы...</td>\n",
       "      <td>[так, думать, молодой, повеса,  \\n, лететь, в,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Служив отлично благоро...</td>\n",
       "      <td>[служив, отлично, благородно,  \\n, долгами, жи...</td>\n",
       "      <td>[служивый, отлично, благородно,  \\n, долг, жит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Когда же юности мятежн...</td>\n",
       "      <td>[когда, же, юности, мятежной,  \\n, пришла, евг...</td>\n",
       "      <td>[когда, же, юность, мятежный,  \\n, прийти, евг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>А счастье было так воз...</td>\n",
       "      <td>[а, счастье, было, так, возможно,  \\n, так, бл...</td>\n",
       "      <td>[а, счастие, быть, так, возможно,  \\n, так, бл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Она ушла. Стоит Евгени...</td>\n",
       "      <td>[она, ушла, стоит, евгений,  \\n, как, будто, г...</td>\n",
       "      <td>[она, уйти, стоить, евгений,  \\n, как, будто, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Кто б ни был ты, о мой...</td>\n",
       "      <td>[кто, б, ни, был, ты, о, мой, читатель,  \\n, д...</td>\n",
       "      <td>[кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Прости ж и ты, мой спу...</td>\n",
       "      <td>[прости, ж, и, ты, мой, спутник, странный,  \\n...</td>\n",
       "      <td>[простить, ж, и, ты, мой, спутник, странный,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Но те, которым в дружн...</td>\n",
       "      <td>[но, те, которым, в, дружной, встрече,  \\n, я,...</td>\n",
       "      <td>[но, тот, который, в, дружный, встреча,  \\n, я...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content  \\\n",
       "0                            Не мысля гордый свет з...   \n",
       "1                            \"Мой дядя самых честны...   \n",
       "2                            Так думал молодой пове...   \n",
       "3                            Служив отлично благоро...   \n",
       "4                            Когда же юности мятежн...   \n",
       "..                                                 ...   \n",
       "371                          А счастье было так воз...   \n",
       "372                          Она ушла. Стоит Евгени...   \n",
       "373                          Кто б ни был ты, о мой...   \n",
       "374                          Прости ж и ты, мой спу...   \n",
       "375                          Но те, которым в дружн...   \n",
       "\n",
       "                                       Content_splited  \\\n",
       "0    [не, мысля, гордый, свет, забавить,  \\n, внима...   \n",
       "1    [мой, дядя, самых, честных, правил,  \\n, когда...   \n",
       "2    [так, думал, молодой, повеса,  \\n, летя, в, пы...   \n",
       "3    [служив, отлично, благородно,  \\n, долгами, жи...   \n",
       "4    [когда, же, юности, мятежной,  \\n, пришла, евг...   \n",
       "..                                                 ...   \n",
       "371  [а, счастье, было, так, возможно,  \\n, так, бл...   \n",
       "372  [она, ушла, стоит, евгений,  \\n, как, будто, г...   \n",
       "373  [кто, б, ни, был, ты, о, мой, читатель,  \\n, д...   \n",
       "374  [прости, ж, и, ты, мой, спутник, странный,  \\n...   \n",
       "375  [но, те, которым, в, дружной, встрече,  \\n, я,...   \n",
       "\n",
       "                                 Content_splited_morph  \n",
       "0    [не, мыслить, гордый, свет, забавить,  \\n, вни...  \n",
       "1    [мой, дядя, самый, честной, правило,  \\n, когд...  \n",
       "2    [так, думать, молодой, повеса,  \\n, лететь, в,...  \n",
       "3    [служивый, отлично, благородно,  \\n, долг, жит...  \n",
       "4    [когда, же, юность, мятежный,  \\n, прийти, евг...  \n",
       "..                                                 ...  \n",
       "371  [а, счастие, быть, так, возможно,  \\n, так, бл...  \n",
       "372  [она, уйти, стоить, евгений,  \\n, как, будто, ...  \n",
       "373  [кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...  \n",
       "374  [простить, ж, и, ты, мой, спутник, странный,  ...  \n",
       "375  [но, тот, который, в, дружный, встреча,  \\n, я...  \n",
       "\n",
       "[376 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def exclude_punctuation(txt):\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)    \n",
    "    txt = re.sub(\"\\n\", \" \\n\", txt)    \n",
    "    return txt\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(txt, morph = False):\n",
    "    txt = str(txt)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\n\", \"zzz\", txt)\n",
    "    new_txt =[]\n",
    "    for word in txt.split():\n",
    "        if word == \"zzz\":\n",
    "            word = \" \\n\"\n",
    "            \n",
    "        else:\n",
    "            if morph:\n",
    "                word = morpher.parse(word)[0].normal_form\n",
    "            else:\n",
    "                pass\n",
    "        new_txt.append(word)\n",
    "\n",
    "    return new_txt\n",
    "\n",
    "\n",
    "data['Content_splited'] = data['Content'].apply(exclude_punctuation)\n",
    "\n",
    "\n",
    "data['Content_splited_morph'] = data['Content_splited'].apply(preprocess_text, morph = True)\n",
    "data['Content_splited'] = data['Content_splited'].apply(preprocess_text, morph = False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed34dc57",
   "metadata": {},
   "source": [
    "dump = list(data['Content_splited'].values)\n",
    "\n",
    "\n",
    "dump_txt_split = []\n",
    "for sublist in dump:\n",
    "    for item in sublist:\n",
    "        dump_txt_split.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd0321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8427 8427 8427\n",
      "5047 5047 5047\n"
     ]
    }
   ],
   "source": [
    "def get_w2i_i2w(column_data):\n",
    "    \n",
    "    dump = list(column_data.values)\n",
    "    dump_txt_split = []\n",
    "    for sublist in dump:\n",
    "        for item in sublist:\n",
    "            dump_txt_split.append(item)\n",
    "\n",
    "\n",
    "    vocab = sorted(set(dump_txt_split))\n",
    "#    print('{} unique characters'.format(len(vocab)))            \n",
    "            \n",
    "    # Creating a mapping from unique characters to indices\n",
    "    word2idx = {u:i for i, u in enumerate(vocab)}\n",
    "    idx2word = np.array(vocab)\n",
    "    \n",
    "    print(len(vocab), len(word2idx), len(idx2word))\n",
    "    return word2idx, idx2word\n",
    "    \n",
    "\n",
    "word2idx, idx2word = get_w2i_i2w(data['Content_splited'])    \n",
    "word2idx_morph, idx2word_morph = get_w2i_i2w(data['Content_splited_morph'])    \n",
    "    \n",
    "data['int_Content_splited'] = data['Content_splited'].apply(lambda x: [word2idx[c] for c in x])\n",
    "data['int_Content_splited_morph'] = data['Content_splited_morph'].apply(lambda x: [word2idx_morph[c] for c in x])            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a754e738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_splited</th>\n",
       "      <th>Content_splited_morph</th>\n",
       "      <th>int_Content_splited</th>\n",
       "      <th>int_Content_splited_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не мысля гордый свет з...</td>\n",
       "      <td>[не, мысля, гордый, свет, забавить,  \\n, внима...</td>\n",
       "      <td>[не, мыслить, гордый, свет, забавить,  \\n, вни...</td>\n",
       "      <td>[3817, 3634, 1358, 6327, 2071, 0, 878, 1844, 9...</td>\n",
       "      <td>[2253, 2140, 844, 3827, 1222, 0, 556, 1095, 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Мой дядя самых честны...</td>\n",
       "      <td>[мой, дядя, самых, честных, правил,  \\n, когда...</td>\n",
       "      <td>[мой, дядя, самый, честной, правило,  \\n, когд...</td>\n",
       "      <td>[3487, 1912, 6292, 8129, 5394, 0, 2788, 3817, ...</td>\n",
       "      <td>[2064, 1134, 3798, 4875, 3259, 0, 1664, 2253, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Так думал молодой пове...</td>\n",
       "      <td>[так, думал, молодой, повеса,  \\n, летя, в, пы...</td>\n",
       "      <td>[так, думать, молодой, повеса,  \\n, лететь, в,...</td>\n",
       "      <td>[7249, 1867, 3505, 4930, 0, 3102, 565, 5872, 3...</td>\n",
       "      <td>[4324, 1110, 2077, 2953, 0, 1860, 384, 3553, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Служив отлично благоро...</td>\n",
       "      <td>[служив, отлично, благородно,  \\n, долгами, жи...</td>\n",
       "      <td>[служивый, отлично, благородно,  \\n, долг, жит...</td>\n",
       "      <td>[6660, 4535, 325, 0, 1720, 2041, 1919, 4512, 0...</td>\n",
       "      <td>[4007, 2710, 254, 0, 1039, 1204, 2602, 2692, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Когда же юности мятежн...</td>\n",
       "      <td>[когда, же, юности, мятежной,  \\n, пришла, евг...</td>\n",
       "      <td>[когда, же, юность, мятежный,  \\n, прийти, евг...</td>\n",
       "      <td>[2788, 1980, 8363, 3638, 0, 5651, 1915, 5222, ...</td>\n",
       "      <td>[1664, 1168, 5011, 2144, 0, 3352, 1135, 3151, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>А счастье было так воз...</td>\n",
       "      <td>[а, счастье, было, так, возможно,  \\n, так, бл...</td>\n",
       "      <td>[а, счастие, быть, так, возможно,  \\n, так, бл...</td>\n",
       "      <td>[98, 7202, 550, 7249, 924, 0, 7249, 380, 4072,...</td>\n",
       "      <td>[98, 4295, 383, 4324, 584, 0, 4324, 279, 2421,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Она ушла. Стоит Евгени...</td>\n",
       "      <td>[она, ушла, стоит, евгений,  \\n, как, будто, г...</td>\n",
       "      <td>[она, уйти, стоить, евгений,  \\n, как, будто, ...</td>\n",
       "      <td>[4371, 7870, 7006, 1914, 0, 2637, 515, 1462, 5...</td>\n",
       "      <td>[2603, 4579, 4199, 1135, 0, 1571, 361, 899, 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Кто б ни был ты, о мой...</td>\n",
       "      <td>[кто, б, ни, был, ты, о, мой, читатель,  \\n, д...</td>\n",
       "      <td>[кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...</td>\n",
       "      <td>[2960, 160, 4037, 546, 7548, 4141, 3487, 8153,...</td>\n",
       "      <td>[1780, 151, 2398, 383, 4493, 2453, 2064, 4888,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Прости ж и ты, мой спу...</td>\n",
       "      <td>[прости, ж, и, ты, мой, спутник, странный,  \\n...</td>\n",
       "      <td>[простить, ж, и, ты, мой, спутник, странный,  ...</td>\n",
       "      <td>[5751, 1951, 2446, 7548, 3487, 6916, 7049, 0, ...</td>\n",
       "      <td>[3477, 1153, 1454, 4493, 2064, 4156, 4222, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Но те, которым в дружн...</td>\n",
       "      <td>[но, те, которым, в, дружной, встрече,  \\n, я,...</td>\n",
       "      <td>[но, тот, который, в, дружный, встреча,  \\n, я...</td>\n",
       "      <td>[4072, 7309, 2876, 565, 1849, 1132, 0, 8375, 7...</td>\n",
       "      <td>[2421, 4426, 1729, 384, 1099, 702, 0, 5016, 42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content  \\\n",
       "0                            Не мысля гордый свет з...   \n",
       "1                            \"Мой дядя самых честны...   \n",
       "2                            Так думал молодой пове...   \n",
       "3                            Служив отлично благоро...   \n",
       "4                            Когда же юности мятежн...   \n",
       "..                                                 ...   \n",
       "371                          А счастье было так воз...   \n",
       "372                          Она ушла. Стоит Евгени...   \n",
       "373                          Кто б ни был ты, о мой...   \n",
       "374                          Прости ж и ты, мой спу...   \n",
       "375                          Но те, которым в дружн...   \n",
       "\n",
       "                                       Content_splited  \\\n",
       "0    [не, мысля, гордый, свет, забавить,  \\n, внима...   \n",
       "1    [мой, дядя, самых, честных, правил,  \\n, когда...   \n",
       "2    [так, думал, молодой, повеса,  \\n, летя, в, пы...   \n",
       "3    [служив, отлично, благородно,  \\n, долгами, жи...   \n",
       "4    [когда, же, юности, мятежной,  \\n, пришла, евг...   \n",
       "..                                                 ...   \n",
       "371  [а, счастье, было, так, возможно,  \\n, так, бл...   \n",
       "372  [она, ушла, стоит, евгений,  \\n, как, будто, г...   \n",
       "373  [кто, б, ни, был, ты, о, мой, читатель,  \\n, д...   \n",
       "374  [прости, ж, и, ты, мой, спутник, странный,  \\n...   \n",
       "375  [но, те, которым, в, дружной, встрече,  \\n, я,...   \n",
       "\n",
       "                                 Content_splited_morph  \\\n",
       "0    [не, мыслить, гордый, свет, забавить,  \\n, вни...   \n",
       "1    [мой, дядя, самый, честной, правило,  \\n, когд...   \n",
       "2    [так, думать, молодой, повеса,  \\n, лететь, в,...   \n",
       "3    [служивый, отлично, благородно,  \\n, долг, жит...   \n",
       "4    [когда, же, юность, мятежный,  \\n, прийти, евг...   \n",
       "..                                                 ...   \n",
       "371  [а, счастие, быть, так, возможно,  \\n, так, бл...   \n",
       "372  [она, уйти, стоить, евгений,  \\n, как, будто, ...   \n",
       "373  [кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...   \n",
       "374  [простить, ж, и, ты, мой, спутник, странный,  ...   \n",
       "375  [но, тот, который, в, дружный, встреча,  \\n, я...   \n",
       "\n",
       "                                   int_Content_splited  \\\n",
       "0    [3817, 3634, 1358, 6327, 2071, 0, 878, 1844, 9...   \n",
       "1    [3487, 1912, 6292, 8129, 5394, 0, 2788, 3817, ...   \n",
       "2    [7249, 1867, 3505, 4930, 0, 3102, 565, 5872, 3...   \n",
       "3    [6660, 4535, 325, 0, 1720, 2041, 1919, 4512, 0...   \n",
       "4    [2788, 1980, 8363, 3638, 0, 5651, 1915, 5222, ...   \n",
       "..                                                 ...   \n",
       "371  [98, 7202, 550, 7249, 924, 0, 7249, 380, 4072,...   \n",
       "372  [4371, 7870, 7006, 1914, 0, 2637, 515, 1462, 5...   \n",
       "373  [2960, 160, 4037, 546, 7548, 4141, 3487, 8153,...   \n",
       "374  [5751, 1951, 2446, 7548, 3487, 6916, 7049, 0, ...   \n",
       "375  [4072, 7309, 2876, 565, 1849, 1132, 0, 8375, 7...   \n",
       "\n",
       "                             int_Content_splited_morph  \n",
       "0    [2253, 2140, 844, 3827, 1222, 0, 556, 1095, 58...  \n",
       "1    [2064, 1134, 3798, 4875, 3259, 0, 1664, 2253, ...  \n",
       "2    [4324, 1110, 2077, 2953, 0, 1860, 384, 3553, 2...  \n",
       "3    [4007, 2710, 254, 0, 1039, 1204, 2602, 2692, 0...  \n",
       "4    [1664, 1168, 5011, 2144, 0, 3352, 1135, 3151, ...  \n",
       "..                                                 ...  \n",
       "371  [98, 4295, 383, 4324, 584, 0, 4324, 279, 2421,...  \n",
       "372  [2603, 4579, 4199, 1135, 0, 1571, 361, 899, 31...  \n",
       "373  [1780, 151, 2398, 383, 4493, 2453, 2064, 4888,...  \n",
       "374  [3477, 1153, 1454, 4493, 2064, 4156, 4222, 0, ...  \n",
       "375  [2421, 4426, 1729, 384, 1099, 702, 0, 5016, 42...  \n",
       "\n",
       "[376 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd601f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 68)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 100\n",
    "len(data.iloc[i]['int_Content_splited']), len(data.iloc[i]['int_Content_splited_morph'])\n",
    "#data.iloc[i]['int_Content_splited_morph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e601ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_int(column_data):\n",
    "    \n",
    "    int_dump = column_data.values\n",
    "    all_txt_as_int = []\n",
    "\n",
    "    for sublist in int_dump:\n",
    "        for item in sublist:\n",
    "            all_txt_as_int.append(item)\n",
    "    all_txt_as_int = np.array(all_txt_as_int)    \n",
    "    \n",
    "    return all_txt_as_int\n",
    "\n",
    "all_txt_as_int = get_all_int(data['int_Content_splited'])\n",
    "\n",
    "all_txt_as_int_morph = get_all_int(data['int_Content_splited_morph'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd204a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27414, 27414)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_txt_as_int), len(all_txt_as_int_morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebee674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: (((10,), (10,)), (10,)), types: ((tf.int32, tf.int32), tf.int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 10\n",
    "examples_per_epoch = len(all_txt_as_int)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(all_txt_as_int)\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(all_txt_as_int_morph)\n",
    "\n",
    "sequences1 = dataset1.batch(seq_length+1, drop_remainder=True)\n",
    "sequences2 = dataset2.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "def split_input_morph(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    return input_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset1 = sequences1.map(split_input_target)\n",
    "dataset2 = sequences2.map(split_input_morph)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ce066cd",
   "metadata": {},
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:,0]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "dataset\n",
    "#for element in dataset:\n",
    "#      print(element)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26734247",
   "metadata": {},
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(' '.join(idx2word[input_example.numpy()])))\n",
    "    print('Target data:', repr(' '.join(idx2word[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c7e4e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (((64, 10), (64, 10)), (64, 10)), types: ((tf.int32, tf.int32), tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f493495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(idx2word)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e05c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  \n",
    "    \n",
    "    inputs = tf.keras.layers.Input(batch_input_shape=[batch_size, None])\n",
    "\n",
    "    x =     tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
    "    print(x.shape)\n",
    "    x1 = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(x)\n",
    "    x = tf.keras.layers.concatenate([x,x1], axis=-1)\n",
    "    \n",
    "    print(x.shape)\n",
    "    x2 = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(x)\n",
    "    x = tf.keras.layers.add([x,x2])\n",
    "    \n",
    "    print(x.shape)\n",
    "    x3 = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(x)   \n",
    "    \n",
    "    x = tf.keras.layers.add([x,x3])\n",
    "    \n",
    "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size))(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    print('==================================================')\n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs_morph = tf.keras.layers.Input(batch_input_shape=[batch_size, None])\n",
    "\n",
    "    xm =     tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs_morph)\n",
    "    print(xm.shape)\n",
    "    x1m = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(xm)\n",
    "    xm = tf.keras.layers.concatenate([xm,x1m], axis=-1)\n",
    "    \n",
    "    print(xm.shape)\n",
    "    x2m = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(xm)\n",
    "    xm = tf.keras.layers.add([xm,x2m])\n",
    "    \n",
    "    print(xm.shape)\n",
    "    x3m = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(xm)   \n",
    "    \n",
    "    xm = tf.keras.layers.add([xm,x3m])\n",
    "    \n",
    "    \n",
    "    \n",
    "    xm = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size))(xm)\n",
    "    print(xm.shape)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, xm])      \n",
    "    \n",
    "    x = tf.keras.layers.Dense(vocab_size)(x)    \n",
    "    \n",
    "    \n",
    "    model =tf.keras. Model(inputs=[inputs, inputs_morph], outputs=x)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50cc0987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, None, 256)\n",
      "(64, None, 1280)\n",
      "(64, None, 1280)\n",
      "(64, None, 8427)\n",
      "==================================================\n",
      "(64, None, 256)\n",
      "(64, None, 1280)\n",
      "(64, None, 1280)\n",
      "(64, None, 8427)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b697ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(64, None)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(64, None)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (64, None, 256)      2157312     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (64, None, 256)      2157312     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (64, None, 1024)     3938304     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (64, None, 1024)     3938304     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (64, None, 1280)     0           embedding[0][0]                  \n",
      "                                                                 gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (64, None, 1280)     0           embedding_1[0][0]                \n",
      "                                                                 gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (64, None, 1280)     9838080     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (64, None, 1280)     9838080     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (64, None, 1280)     0           concatenate[0][0]                \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (64, None, 1280)     0           concatenate_1[0][0]              \n",
      "                                                                 gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (64, None, 1280)     9838080     add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     (64, None, 1280)     9838080     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (64, None, 1280)     0           add[0][0]                        \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (64, None, 1280)     0           add_2[0][0]                      \n",
      "                                                                 gru_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (64, None, 8427)     10794987    add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (64, None, 8427)     10794987    add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (64, None, 16854)    0           time_distributed[0][0]           \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (64, None, 8427)     142037085   concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 215,170,611\n",
      "Trainable params: 215,170,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd45582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d45af0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e8df676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    period=10,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d4ace08",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4e86caa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 14s 218ms/step - loss: 6.0966\n",
      "38/38 [==============================] - 8s 217ms/step - loss: 3.5173\n",
      "38/38 [==============================] - 8s 220ms/step - loss: 1.6952\n",
      "38/38 [==============================] - 8s 221ms/step - loss: 0.4878\n",
      "38/38 [==============================] - 8s 219ms/step - loss: 0.1242\n",
      "38/38 [==============================] - 8s 218ms/step - loss: 0.0480\n",
      "38/38 [==============================] - 8s 218ms/step - loss: 0.0241\n",
      "38/38 [==============================] - 8s 220ms/step - loss: 0.0193\n",
      "38/38 [==============================] - 8s 218ms/step - loss: 0.0156\n",
      "38/38 [==============================] - 8s 220ms/step - loss: 0.0122\n",
      "38/38 [==============================] - 8s 218ms/step - loss: 0.0133\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    model.fit(dataset, epochs=1, callbacks=[checkpoint_callback])\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fba8992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc837e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, None, 256)\n",
      "(1, None, 1280)\n",
      "(1, None, 1280)\n",
      "(1, None, 8427)\n",
      "==================================================\n",
      "(1, None, 256)\n",
      "(1, None, 1280)\n",
      "(1, None, 1280)\n",
      "(1, None, 8427)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e8f1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of Words to generate\n",
    "    num_generate = 30\n",
    "\n",
    "    \n",
    "    start_string = exclude_punctuation(start_string)\n",
    "    #print(start_string)\n",
    "    start_string_asis = preprocess_text(start_string, morph = False)\n",
    "    start_string_morph = preprocess_text(start_string, morph = True)    \n",
    "\n",
    "      \n",
    "    \n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [word2idx[s] for s in start_string_asis]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    input_eval_morph = [word2idx_morph[s] for s in start_string_morph]\n",
    "    input_eval_morph = tf.expand_dims(input_eval_morph, 0)\n",
    "     \n",
    "    \n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model([input_eval, input_eval_morph])\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        a=preprocess_text(idx2word[predicted_id], morph = True)\n",
    "        predicted_id_morph=word2idx_morph[a[0]]\n",
    "        \n",
    "        \n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)       \n",
    "        input_eval_morph = tf.expand_dims([predicted_id_morph], 0)\n",
    "                \n",
    "        text_generated.append(idx2word[predicted_id])\n",
    "\n",
    "    return (start_string + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17d1a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Святой исполненной мечты жестокая высокие вечор братцы благословенное дрогнет пепел обряд конюшня дружба ближний безбожно дрогнет незваных звала горькую гремел вновь бытописания блистает беспечна безбожно ветреное вперил замечая гостях вменяя былей близ беседуют\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"Святой исполненной мечты \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b83751a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мой дядя самых честных правил людьми пламенный красотой золотой высока беспечна безбожно мрак завез оплошного бровями веселья бородатый благоразумной никогда знал гремел вновь бытописания блистает беспечна безбожно ветреное петербургский до воспела веков дружеский заняв дидло\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"Мой дядя самых честных правил? \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ff29451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мой дядя самых честных правил  \n",
      " \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"Мой дядя самых честных правил \\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af30d7b",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3625e",
   "metadata": {},
   "source": [
    "Качество генерируемого текста оставляет желать лучшего. Использование двух \"голов\" не привело к улучшению качества текста."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
