{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a6110c",
   "metadata": {},
   "source": [
    "# HW 9 ONE HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20134083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba3db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'evgenyi_onegin.txt'\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "text = text.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd9fb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                        \"Мой дядя самых честных правил,\\n                        Когда не в шутку занемог,\\n                        Он уважать себя заставил\\n                        И лучше выдумать не мог.\\n                        Его пример другим наука;\\n                        Но, боже мой, какая скука\\n                        С больным сидеть и день и ночь,\\n                        Не отходя ни шагу прочь!\\n                        Какое низкое коварство\\n                        Полуживого забавлять,\\n                        Ему подушки поправлять,\\n                        Печально подносить лекарство,\\n                        Вздыхать и думать про себя:\\n                        Когда же черт возьмет тебя!\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89d5aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333d105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only = []\n",
    "for strofa in text:\n",
    "    if len(strofa) < 350:\n",
    "        continue\n",
    "    else:\n",
    "        text_only.append(strofa)\n",
    "len(text_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88eb5edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                        Кого ж любить? Кому же верить?\\n                        Кто не изменит нам один?\\n                        Кто все дела, все речи мерит\\n                        Услужливо на наш аршин?\\n                        Кто клеветы про нас не сеет?\\n                        Кто нас заботливо лелеет?\\n                        Кому порок наш не беда?\\n                        Кто не наскучит никогда?\\n                        Призрака суетный искатель,\\n                        Трудов напрасно не губя,\\n                        Любите самого себя,\\n                        Достопочтенный мой читатель!\\n                        Предмет достойный: ничего\\n                        Любезней, верно, нет его.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only[155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4bd110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не мысля гордый свет з...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Мой дядя самых честны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Так думал молодой пове...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Служив отлично благоро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Когда же юности мятежн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>А счастье было так воз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Она ушла. Стоит Евгени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Кто б ни был ты, о мой...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Прости ж и ты, мой спу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Но те, которым в дружн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content\n",
       "0                            Не мысля гордый свет з...\n",
       "1                            \"Мой дядя самых честны...\n",
       "2                            Так думал молодой пове...\n",
       "3                            Служив отлично благоро...\n",
       "4                            Когда же юности мятежн...\n",
       "..                                                 ...\n",
       "371                          А счастье было так воз...\n",
       "372                          Она ушла. Стоит Евгени...\n",
       "373                          Кто б ни был ты, о мой...\n",
       "374                          Прости ж и ты, мой спу...\n",
       "375                          Но те, которым в дружн...\n",
       "\n",
       "[376 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(text_only)\n",
    "data = data.rename(columns={0: \"Content\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f163f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_splited</th>\n",
       "      <th>Content_splited_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не мысля гордый свет з...</td>\n",
       "      <td>[не, мысля, гордый, свет, забавить,  \\n, внима...</td>\n",
       "      <td>[не, мыслить, гордый, свет, забавить,  \\n, вни...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Мой дядя самых честны...</td>\n",
       "      <td>[мой, дядя, самых, честных, правил,  \\n, когда...</td>\n",
       "      <td>[мой, дядя, самый, честной, правило,  \\n, когд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Так думал молодой пове...</td>\n",
       "      <td>[так, думал, молодой, повеса,  \\n, летя, в, пы...</td>\n",
       "      <td>[так, думать, молодой, повеса,  \\n, лететь, в,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Служив отлично благоро...</td>\n",
       "      <td>[служив, отлично, благородно,  \\n, долгами, жи...</td>\n",
       "      <td>[служивый, отлично, благородно,  \\n, долг, жит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Когда же юности мятежн...</td>\n",
       "      <td>[когда, же, юности, мятежной,  \\n, пришла, евг...</td>\n",
       "      <td>[когда, же, юность, мятежный,  \\n, прийти, евг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>А счастье было так воз...</td>\n",
       "      <td>[а, счастье, было, так, возможно,  \\n, так, бл...</td>\n",
       "      <td>[а, счастие, быть, так, возможно,  \\n, так, бл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Она ушла. Стоит Евгени...</td>\n",
       "      <td>[она, ушла, стоит, евгений,  \\n, как, будто, г...</td>\n",
       "      <td>[она, уйти, стоить, евгений,  \\n, как, будто, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Кто б ни был ты, о мой...</td>\n",
       "      <td>[кто, б, ни, был, ты, о, мой, читатель,  \\n, д...</td>\n",
       "      <td>[кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Прости ж и ты, мой спу...</td>\n",
       "      <td>[прости, ж, и, ты, мой, спутник, странный,  \\n...</td>\n",
       "      <td>[простить, ж, и, ты, мой, спутник, странный,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Но те, которым в дружн...</td>\n",
       "      <td>[но, те, которым, в, дружной, встрече,  \\n, я,...</td>\n",
       "      <td>[но, тот, который, в, дружный, встреча,  \\n, я...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content  \\\n",
       "0                            Не мысля гордый свет з...   \n",
       "1                            \"Мой дядя самых честны...   \n",
       "2                            Так думал молодой пове...   \n",
       "3                            Служив отлично благоро...   \n",
       "4                            Когда же юности мятежн...   \n",
       "..                                                 ...   \n",
       "371                          А счастье было так воз...   \n",
       "372                          Она ушла. Стоит Евгени...   \n",
       "373                          Кто б ни был ты, о мой...   \n",
       "374                          Прости ж и ты, мой спу...   \n",
       "375                          Но те, которым в дружн...   \n",
       "\n",
       "                                       Content_splited  \\\n",
       "0    [не, мысля, гордый, свет, забавить,  \\n, внима...   \n",
       "1    [мой, дядя, самых, честных, правил,  \\n, когда...   \n",
       "2    [так, думал, молодой, повеса,  \\n, летя, в, пы...   \n",
       "3    [служив, отлично, благородно,  \\n, долгами, жи...   \n",
       "4    [когда, же, юности, мятежной,  \\n, пришла, евг...   \n",
       "..                                                 ...   \n",
       "371  [а, счастье, было, так, возможно,  \\n, так, бл...   \n",
       "372  [она, ушла, стоит, евгений,  \\n, как, будто, г...   \n",
       "373  [кто, б, ни, был, ты, о, мой, читатель,  \\n, д...   \n",
       "374  [прости, ж, и, ты, мой, спутник, странный,  \\n...   \n",
       "375  [но, те, которым, в, дружной, встрече,  \\n, я,...   \n",
       "\n",
       "                                 Content_splited_morph  \n",
       "0    [не, мыслить, гордый, свет, забавить,  \\n, вни...  \n",
       "1    [мой, дядя, самый, честной, правило,  \\n, когд...  \n",
       "2    [так, думать, молодой, повеса,  \\n, лететь, в,...  \n",
       "3    [служивый, отлично, благородно,  \\n, долг, жит...  \n",
       "4    [когда, же, юность, мятежный,  \\n, прийти, евг...  \n",
       "..                                                 ...  \n",
       "371  [а, счастие, быть, так, возможно,  \\n, так, бл...  \n",
       "372  [она, уйти, стоить, евгений,  \\n, как, будто, ...  \n",
       "373  [кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...  \n",
       "374  [простить, ж, и, ты, мой, спутник, странный,  ...  \n",
       "375  [но, тот, который, в, дружный, встреча,  \\n, я...  \n",
       "\n",
       "[376 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def exclude_punctuation(txt):\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)    \n",
    "    txt = re.sub(\"\\n\", \" \\n\", txt)    \n",
    "    return txt\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(txt, morph = False):\n",
    "    txt = str(txt)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\n\", \"zzz\", txt)\n",
    "    new_txt =[]\n",
    "    for word in txt.split():\n",
    "        if word == \"zzz\":\n",
    "            word = \" \\n\"\n",
    "            \n",
    "        else:\n",
    "            if morph:\n",
    "                word = morpher.parse(word)[0].normal_form\n",
    "            else:\n",
    "                pass\n",
    "        new_txt.append(word)\n",
    "\n",
    "    return new_txt\n",
    "\n",
    "\n",
    "data['Content_splited'] = data['Content'].apply(exclude_punctuation)\n",
    "\n",
    "\n",
    "data['Content_splited_morph'] = data['Content_splited'].apply(preprocess_text, morph = True)\n",
    "data['Content_splited'] = data['Content_splited'].apply(preprocess_text, morph = False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0efdb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.iloc[1]['Content_splited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e134e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2i_i2w(column_data):\n",
    "    \n",
    "    dump = list(column_data.values)\n",
    "    dump_txt_split = []\n",
    "    for sublist in dump:\n",
    "        for item in sublist:\n",
    "            dump_txt_split.append(item)\n",
    "\n",
    "\n",
    "    vocab = sorted(set(dump_txt_split))\n",
    "#    print('{} unique characters'.format(len(vocab)))            \n",
    "            \n",
    "    # Creating a mapping from unique characters to indices\n",
    "    word2idx = {u:i for i, u in enumerate(vocab)}\n",
    "    idx2word = np.array(vocab)\n",
    "    \n",
    "    print(len(vocab), len(word2idx), len(idx2word))\n",
    "    return word2idx, idx2word\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb96b5f",
   "metadata": {},
   "source": [
    "Дальше можно работать с одним из двух вариантов.   \n",
    "Первый это с текстом __\"как есть\"__.    \n",
    "Второй с приведенным к __нормальной форме__.\n",
    "\n",
    "Для примера далее работаем с текстом __\"как есть\"__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f26b3bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8427 8427 8427\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word = get_w2i_i2w(data['Content_splited'])        \n",
    "data['int_Content_splited'] = data['Content_splited'].apply(lambda x: [word2idx[c] for c in x])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17d5f76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_splited</th>\n",
       "      <th>Content_splited_morph</th>\n",
       "      <th>int_Content_splited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не мысля гордый свет з...</td>\n",
       "      <td>[не, мысля, гордый, свет, забавить,  \\n, внима...</td>\n",
       "      <td>[не, мыслить, гордый, свет, забавить,  \\n, вни...</td>\n",
       "      <td>[3817, 3634, 1358, 6327, 2071, 0, 878, 1844, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Мой дядя самых честны...</td>\n",
       "      <td>[мой, дядя, самых, честных, правил,  \\n, когда...</td>\n",
       "      <td>[мой, дядя, самый, честной, правило,  \\n, когд...</td>\n",
       "      <td>[3487, 1912, 6292, 8129, 5394, 0, 2788, 3817, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Так думал молодой пове...</td>\n",
       "      <td>[так, думал, молодой, повеса,  \\n, летя, в, пы...</td>\n",
       "      <td>[так, думать, молодой, повеса,  \\n, лететь, в,...</td>\n",
       "      <td>[7249, 1867, 3505, 4930, 0, 3102, 565, 5872, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Служив отлично благоро...</td>\n",
       "      <td>[служив, отлично, благородно,  \\n, долгами, жи...</td>\n",
       "      <td>[служивый, отлично, благородно,  \\n, долг, жит...</td>\n",
       "      <td>[6660, 4535, 325, 0, 1720, 2041, 1919, 4512, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Когда же юности мятежн...</td>\n",
       "      <td>[когда, же, юности, мятежной,  \\n, пришла, евг...</td>\n",
       "      <td>[когда, же, юность, мятежный,  \\n, прийти, евг...</td>\n",
       "      <td>[2788, 1980, 8363, 3638, 0, 5651, 1915, 5222, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>А счастье было так воз...</td>\n",
       "      <td>[а, счастье, было, так, возможно,  \\n, так, бл...</td>\n",
       "      <td>[а, счастие, быть, так, возможно,  \\n, так, бл...</td>\n",
       "      <td>[98, 7202, 550, 7249, 924, 0, 7249, 380, 4072,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Она ушла. Стоит Евгени...</td>\n",
       "      <td>[она, ушла, стоит, евгений,  \\n, как, будто, г...</td>\n",
       "      <td>[она, уйти, стоить, евгений,  \\n, как, будто, ...</td>\n",
       "      <td>[4371, 7870, 7006, 1914, 0, 2637, 515, 1462, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Кто б ни был ты, о мой...</td>\n",
       "      <td>[кто, б, ни, был, ты, о, мой, читатель,  \\n, д...</td>\n",
       "      <td>[кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...</td>\n",
       "      <td>[2960, 160, 4037, 546, 7548, 4141, 3487, 8153,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Прости ж и ты, мой спу...</td>\n",
       "      <td>[прости, ж, и, ты, мой, спутник, странный,  \\n...</td>\n",
       "      <td>[простить, ж, и, ты, мой, спутник, странный,  ...</td>\n",
       "      <td>[5751, 1951, 2446, 7548, 3487, 6916, 7049, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Но те, которым в дружн...</td>\n",
       "      <td>[но, те, которым, в, дружной, встрече,  \\n, я,...</td>\n",
       "      <td>[но, тот, который, в, дружный, встреча,  \\n, я...</td>\n",
       "      <td>[4072, 7309, 2876, 565, 1849, 1132, 0, 8375, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content  \\\n",
       "0                            Не мысля гордый свет з...   \n",
       "1                            \"Мой дядя самых честны...   \n",
       "2                            Так думал молодой пове...   \n",
       "3                            Служив отлично благоро...   \n",
       "4                            Когда же юности мятежн...   \n",
       "..                                                 ...   \n",
       "371                          А счастье было так воз...   \n",
       "372                          Она ушла. Стоит Евгени...   \n",
       "373                          Кто б ни был ты, о мой...   \n",
       "374                          Прости ж и ты, мой спу...   \n",
       "375                          Но те, которым в дружн...   \n",
       "\n",
       "                                       Content_splited  \\\n",
       "0    [не, мысля, гордый, свет, забавить,  \\n, внима...   \n",
       "1    [мой, дядя, самых, честных, правил,  \\n, когда...   \n",
       "2    [так, думал, молодой, повеса,  \\n, летя, в, пы...   \n",
       "3    [служив, отлично, благородно,  \\n, долгами, жи...   \n",
       "4    [когда, же, юности, мятежной,  \\n, пришла, евг...   \n",
       "..                                                 ...   \n",
       "371  [а, счастье, было, так, возможно,  \\n, так, бл...   \n",
       "372  [она, ушла, стоит, евгений,  \\n, как, будто, г...   \n",
       "373  [кто, б, ни, был, ты, о, мой, читатель,  \\n, д...   \n",
       "374  [прости, ж, и, ты, мой, спутник, странный,  \\n...   \n",
       "375  [но, те, которым, в, дружной, встрече,  \\n, я,...   \n",
       "\n",
       "                                 Content_splited_morph  \\\n",
       "0    [не, мыслить, гордый, свет, забавить,  \\n, вни...   \n",
       "1    [мой, дядя, самый, честной, правило,  \\n, когд...   \n",
       "2    [так, думать, молодой, повеса,  \\n, лететь, в,...   \n",
       "3    [служивый, отлично, благородно,  \\n, долг, жит...   \n",
       "4    [когда, же, юность, мятежный,  \\n, прийти, евг...   \n",
       "..                                                 ...   \n",
       "371  [а, счастие, быть, так, возможно,  \\n, так, бл...   \n",
       "372  [она, уйти, стоить, евгений,  \\n, как, будто, ...   \n",
       "373  [кто, б, ни, быть, ты, о, мой, читатель,  \\n, ...   \n",
       "374  [простить, ж, и, ты, мой, спутник, странный,  ...   \n",
       "375  [но, тот, который, в, дружный, встреча,  \\n, я...   \n",
       "\n",
       "                                   int_Content_splited  \n",
       "0    [3817, 3634, 1358, 6327, 2071, 0, 878, 1844, 9...  \n",
       "1    [3487, 1912, 6292, 8129, 5394, 0, 2788, 3817, ...  \n",
       "2    [7249, 1867, 3505, 4930, 0, 3102, 565, 5872, 3...  \n",
       "3    [6660, 4535, 325, 0, 1720, 2041, 1919, 4512, 0...  \n",
       "4    [2788, 1980, 8363, 3638, 0, 5651, 1915, 5222, ...  \n",
       "..                                                 ...  \n",
       "371  [98, 7202, 550, 7249, 924, 0, 7249, 380, 4072,...  \n",
       "372  [4371, 7870, 7006, 1914, 0, 2637, 515, 1462, 5...  \n",
       "373  [2960, 160, 4037, 546, 7548, 4141, 3487, 8153,...  \n",
       "374  [5751, 1951, 2446, 7548, 3487, 6916, 7049, 0, ...  \n",
       "375  [4072, 7309, 2876, 565, 1849, 1132, 0, 8375, 7...  \n",
       "\n",
       "[376 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219b8c7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.iloc[1]['int_Content_splited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d23913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_int(column_data):\n",
    "    \n",
    "    int_dump = column_data.values\n",
    "    all_txt_as_int = []\n",
    "\n",
    "    for sublist in int_dump:\n",
    "        for item in sublist:\n",
    "            all_txt_as_int.append(item)\n",
    "    all_txt_as_int = np.array(all_txt_as_int)    \n",
    "    \n",
    "    return all_txt_as_int\n",
    "\n",
    "all_txt_as_int = get_all_int(data['int_Content_splited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71f861a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "не\n",
      "мысля\n",
      "гордый\n",
      "свет\n",
      "забавить\n",
      " \n",
      "\n",
      "вниманье\n",
      "дружбы\n",
      "возлюбя\n",
      " \n",
      "\n",
      "хотел\n",
      "бы\n",
      "я\n",
      "тебе\n",
      "представить\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 45\n",
    "examples_per_epoch = len(all_txt_as_int)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "word_dataset = tf.data.Dataset.from_tensor_slices(all_txt_as_int)\n",
    "\n",
    "\n",
    "\n",
    "for i in word_dataset.take(15):\n",
    "    print(idx2word[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "517d33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = word_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f548bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "580c978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'не мысля гордый свет забавить  \\n вниманье дружбы возлюбя  \\n хотел бы я тебе представить  \\n залог достойнее тебя  \\n достойнее души прекрасной  \\n святой исполненной мечты  \\n поэзии живой и ясной  \\n высоких дум и простоты  \\n но так и быть рукой пристрастной  \\n'\n",
      "Target data: 'мысля гордый свет забавить  \\n вниманье дружбы возлюбя  \\n хотел бы я тебе представить  \\n залог достойнее тебя  \\n достойнее души прекрасной  \\n святой исполненной мечты  \\n поэзии живой и ясной  \\n высоких дум и простоты  \\n но так и быть рукой пристрастной  \\n прими'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(' '.join(idx2word[input_example.numpy()])))\n",
    "    print('Target data:', repr(' '.join(idx2word[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c588448a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 45), (64, 45)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe1f14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(idx2word)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ecbed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  \n",
    "    \n",
    "    inputs = tf.keras.layers.Input(batch_input_shape=[batch_size, None])\n",
    "\n",
    "    x =     tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
    "    print(x.shape)\n",
    "    x1 = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(x)\n",
    "    x = tf.keras.layers.concatenate([x,x1], axis=-1)\n",
    "    \n",
    "    print(x.shape)\n",
    "    x2 = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(x)\n",
    "    x = tf.keras.layers.add([x,x2])\n",
    "    \n",
    "    print(x.shape)\n",
    "    x3 = tf.keras.layers.GRU(rnn_units+embedding_dim,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform')(x)   \n",
    "    \n",
    "    x = tf.keras.layers.add([x,x3])   \n",
    "    x = tf.keras.layers.Dense(vocab_size)(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    model =tf.keras. Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be72bae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, None, 256)\n",
      "(64, None, 1280)\n",
      "(64, None, 1280)\n",
      "(64, None, 8427)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aba0de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 45, 8427) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79290e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(64, None)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (64, None, 256)      2157312     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (64, None, 1024)     3938304     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (64, None, 1280)     0           embedding[0][0]                  \n",
      "                                                                 gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (64, None, 1280)     9838080     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (64, None, 1280)     0           concatenate[0][0]                \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (64, None, 1280)     9838080     add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (64, None, 1280)     0           add[0][0]                        \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (64, None, 8427)     10794987    add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 36,566,763\n",
      "Trainable params: 36,566,763\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95992a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 45, 8427)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       9.039229\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d49d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d8f73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    period=20,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f51192ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13d38fee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 144ms/step - loss: 8.6291\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 7.3216\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 7.0112\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 6.8837\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 6.7035\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 6.4932\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 6.3026\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 6.1396\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 5.9751\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 5.7793\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 5.5271\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 5.2618\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 4.9253\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 4.6176\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 4.3103\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 3.9595\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 3.6136\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 3.2342\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 2.9017\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 2.5763\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 2.3041\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 2.0568\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 1.8166\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 1.6343\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 1.4405\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 1.2734\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 1.1390\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 1.0037\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.8970\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.8072\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.7234\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.6612\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.5896\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.5386\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.4842\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.4528\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.4264\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.3961\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3823\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3585\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.3361\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3188\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3043\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3012\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.2840\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.2764\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2654\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2596\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2439\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2369\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2336\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2261\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2202\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.2098\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.2030\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1933\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1929\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1909\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1871\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1784\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1783\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1777\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1705\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1605\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1582\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1552\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1502\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.1436\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1427\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1384\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1371\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1367\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.1322\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1330\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1261\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1219\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1237\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1160\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.1127\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1136\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1110\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1088\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1116\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1076\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1053\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1027\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.0995\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0980\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.0985\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0989\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0954\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1005\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0990\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0926\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.0892\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0865\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0848\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0845\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.0860\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0810\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0818\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0805\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0793\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.0772\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0755\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0771\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.0745\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0751\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0752\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.0737\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.0717\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.0712\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0711\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0703\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0710\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0683\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0679\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.0676\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0652\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.0676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0651\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0639\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.0641\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0666\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.0654\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0624\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0650\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.0651\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0613\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.0596\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.0617\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0583\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0591\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0608\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.0586\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.0580\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0582\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.0574\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.0607\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.0585\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0591\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0595\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.0564\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0579\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0601\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0563\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0542\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0558\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0561\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0573\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    model.fit(dataset, epochs=1, callbacks=[checkpoint_callback])\n",
    "    #model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b24105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f02218cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, None, 256)\n",
      "(1, None, 1280)\n",
      "(1, None, 1280)\n",
      "(1, None, 8427)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99e7387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    \n",
    "    start_string = exclude_punctuation(start_string)\n",
    "    #print(start_string)\n",
    "    start_string_asis = preprocess_text(start_string, morph = False)\n",
    "    \n",
    "    # Number of characters to generate\n",
    "    num_generate = 30\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [word2idx[s] for s in start_string_asis]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.3\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2word[predicted_id])\n",
    "\n",
    "    return (start_string + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fc69c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(generate_text(model, start_string=u\"на биржа к \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f405ca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дядя сени именины  \n",
      " в субботу оленька и мать  \n",
      " велели звать и нет причины  \n",
      " тебе на зов не приезжать  \n",
      " но куча будет там народу  \n",
      " и бал блестит\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"дядя \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92d64b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мой дядя  толкнули  \n",
      " и сад над светлою рекою  \n",
      " и умолку улеглись в столовой ненавидеть  \n",
      " любили профили вернее губим  \n",
      " средь обольстительных сетей  \n",
      " разврат бывало хладнокровный  \n",
      " наукой славился\n"
     ]
    }
   ],
   "source": [
    "start_string = \"Мой дядя  \"\n",
    "print(generate_text(model, start_string=start_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc6be3",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d04af7",
   "metadata": {},
   "source": [
    "Качество генерируемого текста лучше чем при использовании двух \"голов\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9db626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
